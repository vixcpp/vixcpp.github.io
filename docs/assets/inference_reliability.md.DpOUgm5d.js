import{_ as e,o as l,c as a,a as t}from"./app.Bt3MQRgu.js";import"./chunks/markjs.l6TISjdC.js";import"./chunks/minisearch.DigTKvvb.js";const k=JSON.parse('{"title":"Reliability","description":"","frontmatter":{},"headers":[],"relativePath":"inference/reliability.md","filePath":"inference/reliability.md","lastUpdated":1770798288000}'),r={name:"inference/reliability.md"};function s(n,i,o,p,d,c){return l(),a("div",null,[...i[0]||(i[0]=[t(`<h1 id="reliability" tabindex="-1">Reliability <a class="header-anchor" href="#reliability" aria-label="Permalink to &quot;Reliability&quot;">​</a></h1><p>This page explains reliability guarantees and failure behavior in Vix Inference.</p><p>Inference in the real world fails for boring reasons:</p><ul><li>provider rate limits</li><li>network timeouts</li><li>model cold starts</li><li>overloaded GPUs</li><li>partial responses during streaming</li><li>invalid JSON from clients</li><li>slow clients or disconnects</li></ul><p>The goal is not &quot;never fail&quot;. The goal is predictable behavior under failure.</p><hr><h2 id="reliability-goals" tabindex="-1">Reliability goals <a class="header-anchor" href="#reliability-goals" aria-label="Permalink to &quot;Reliability goals&quot;">​</a></h2><p>Vix Inference is designed around these principles:</p><ul><li>Fast failure for invalid requests</li><li>Retries for transient provider errors</li><li>Clear error codes and messages</li><li>Safe streaming termination</li><li>Observability (logs + request id)</li><li>No silent partial success</li></ul><hr><h2 id="request-lifecycle" tabindex="-1">Request lifecycle <a class="header-anchor" href="#request-lifecycle" aria-label="Permalink to &quot;Request lifecycle&quot;">​</a></h2><p>A typical request goes through:</p><ol><li>validate input (schema and limits)</li><li>select provider and model</li><li>execute inference with timeouts</li><li>stream or buffer output</li><li>finalize and emit metrics</li></ol><p>If any step fails, Vix returns a structured error.</p><hr><h2 id="timeouts" tabindex="-1">Timeouts <a class="header-anchor" href="#timeouts" aria-label="Permalink to &quot;Timeouts&quot;">​</a></h2><p>Always set timeouts.</p><p>Recommended timeouts:</p><ul><li>connect timeout: 2 to 5 seconds</li><li>first token timeout: 5 to 15 seconds</li><li>total request timeout: 30 to 120 seconds (depends on workload)</li><li>per chunk flush interval: small and constant</li></ul><p>Timeouts must be enforced both:</p><ul><li>at transport level (HTTP / WS)</li><li>at provider level (SDK / HTTP client)</li></ul><hr><h2 id="retries" tabindex="-1">Retries <a class="header-anchor" href="#retries" aria-label="Permalink to &quot;Retries&quot;">​</a></h2><p>Retries should be limited and only for transient failures.</p><p>Good retry candidates:</p><ul><li>429 Too Many Requests</li><li>503 Service Unavailable</li><li>network timeouts</li><li>connection reset</li></ul><p>Bad retry candidates:</p><ul><li>400 Bad Request</li><li>401 Unauthorized</li><li>403 Forbidden</li><li>404 Not Found</li><li>422 Validation errors</li></ul><p>Recommended strategy:</p><ul><li>max attempts: 2 or 3</li><li>exponential backoff</li><li>jitter</li><li>retry budget per request</li></ul><hr><h2 id="idempotency" tabindex="-1">Idempotency <a class="header-anchor" href="#idempotency" aria-label="Permalink to &quot;Idempotency&quot;">​</a></h2><p>Inference is usually safe to retry because:</p><ul><li>it does not mutate server state</li><li>it returns generated text</li></ul><p>But streaming can duplicate partial tokens if you retry mid-stream.</p><p>If you support retries on the client:</p><ul><li>retry only before the first token</li><li>or use an idempotency key and server-side replay</li></ul><hr><h2 id="streaming-reliability" tabindex="-1">Streaming reliability <a class="header-anchor" href="#streaming-reliability" aria-label="Permalink to &quot;Streaming reliability&quot;">​</a></h2><p>Streaming has extra failure modes:</p><ul><li>client disconnects mid-stream</li><li>provider disconnects mid-stream</li><li>chunk parsing errors</li><li>backpressure and slow readers</li></ul><p>Rules:</p><ul><li>detect disconnect and cancel inference</li><li>always send an explicit end event when possible</li><li>do not keep streaming forever</li><li>cap total streamed bytes</li></ul><p>Recommended events:</p><ul><li><code>inference.start</code></li><li><code>inference.token</code></li><li><code>inference.error</code></li><li><code>inference.end</code></li></ul><p>If the client disconnects, Vix must stop work quickly.</p><hr><h2 id="circuit-breaker" tabindex="-1">Circuit breaker <a class="header-anchor" href="#circuit-breaker" aria-label="Permalink to &quot;Circuit breaker&quot;">​</a></h2><p>If a provider is failing repeatedly, stop sending traffic to it.</p><p>A minimal circuit breaker uses:</p><ul><li>failure counter in a short window</li><li>open state for a cooldown period</li><li>half-open probe requests</li></ul><p>This protects your system from cascading failure.</p><hr><h2 id="fallback-providers" tabindex="-1">Fallback providers <a class="header-anchor" href="#fallback-providers" aria-label="Permalink to &quot;Fallback providers&quot;">​</a></h2><p>If you configure multiple providers, you can fail over.</p><p>Example behavior:</p><ul><li>prefer local provider</li><li>if it fails with timeout or 503, try remote provider</li><li>if all fail, return an error with attempts info</li></ul><p>Failover must be visible in logs and metrics.</p><hr><h2 id="error-format" tabindex="-1">Error format <a class="header-anchor" href="#error-format" aria-label="Permalink to &quot;Error format&quot;">​</a></h2><p>A reliable API returns predictable errors.</p><p>Recommended error envelope:</p><div class="language-json vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">json</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;ok&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">false</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;error&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: {</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;code&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;provider_timeout&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;message&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Provider did not respond in time&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    &quot;retryable&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">  },</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">  &quot;request_id&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;....&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>For streaming, send the same envelope inside <code>inference.error</code>.</p><hr><h2 id="limits" tabindex="-1">Limits <a class="header-anchor" href="#limits" aria-label="Permalink to &quot;Limits&quot;">​</a></h2><p>Reliability includes protecting resources.</p><p>Common limits:</p><ul><li>max input tokens</li><li>max output tokens</li><li>max request body bytes</li><li>max concurrent streams</li><li>max requests per minute per key</li><li>max streaming duration</li></ul><p>Reject early with a clear 4xx error.</p><hr><h2 id="observability" tabindex="-1">Observability <a class="header-anchor" href="#observability" aria-label="Permalink to &quot;Observability&quot;">​</a></h2><p>To debug production failures you need:</p><ul><li>request id in every response</li><li>structured logs (provider, model, latency)</li><li>metrics (p50/p95/p99, error rates)</li><li>retry counts and final reason</li></ul><p>Minimal log fields:</p><ul><li>request_id</li><li>provider</li><li>model</li><li>status</li><li>latency_ms</li><li>retry_count</li><li>streaming (true/false)</li></ul><hr><h2 id="practical-checklist" tabindex="-1">Practical checklist <a class="header-anchor" href="#practical-checklist" aria-label="Permalink to &quot;Practical checklist&quot;">​</a></h2><p>Before shipping:</p><ul><li>timeouts configured</li><li>input validation enforced</li><li>retry policy defined</li><li>streaming end event implemented</li><li>circuit breaker enabled</li><li>rate limit enabled</li><li>logs and metrics enabled</li></ul><p>Reliability is not a feature. It is the default behavior.</p>`,81)])])}const f=e(r,[["render",s]]);export{k as __pageData,f as default};
